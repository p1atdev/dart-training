{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "from optimum.onnxruntime.configuration import (\n",
    "    AutoQuantizationConfig,\n",
    ")\n",
    "from optimum.onnxruntime import ORTQuantizer, ORTModelForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"p1atdev/dart-v1-sft\"\n",
    "save_directory = \"./onnx/sft-q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model from transformers and export it to ONNX\n",
    "ort_model = ORTModelForCausalLM.from_pretrained(model_checkpoint, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the quantization methodology\n",
    "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
    "quantizer = ORTQuantizer.from_pretrained(ort_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dynamic quantizer: QOperator (mode: IntegerOps, schema: u8/s8, channel-wise: False)\n",
      "Quantizing model...\n",
      "Saving quantized model at: onnx\\sft-q (external data format: False)\n",
      "Configuration saved in onnx\\sft-q\\ort_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('onnx/sft-q')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.quantize(save_dir=save_directory, quantization_config=qconfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
